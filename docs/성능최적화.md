# 성능 최적화 상세 설계 (요청 순서 반영)

이 문서는 현재 코드베이스를 기반으로 성능 최적화 전략을 상세하게 정의한다. 각 항목은 "어디에 적용할지", "왜 필요한지", "어떻게 구현할지", "기대 효과"를 포함한다. 코드 예시는 현재 구조(Next.js App Router, BFF 라우트, widgets/features/shared 구조)를 기준으로 작성한다.

본 문서는 설계 문서이며, 실제 적용은 각 항목별 구현 브랜치에서 진행한다.

---

## [1] BFF 데이터 집계

### 1.1 기존 화면 데이터 요청 구조

현재 서비스의 주요 화면은 화면 진입 시 필요한 데이터를 각 위젯 또는 훅 단위로 개별 호출하는 방식으로 구성되어 있다. 이 방식은 기능 단위로 보면 명확하지만, 화면 단위에서 보면 하나의 화면을 만들기 위해 여러 API 요청이 동시에 발생한다는 특징을 갖는다.

예를 들어 채팅 리스트 화면에서는 다음 호출이 동시에 실행된다.

- 로그인된 사용자 정보를 가져오기 위한 `getUserMe()`
- 사용자의 채팅방 목록을 가져오기 위한 `getChatList()`

실제 구현은 `Promise.allSettled` 기반 병렬 호출이며, 응답 도착 시점에 맞춰 화면 상태가 갱신된다. 이 구조는 네트워크 왕복 수가 많고, 도착 순서가 일정하지 않아 화면 상태가 흔들릴 가능성이 높다.

### 1.2 실제로 발생한 문제

이 구조의 첫 번째 문제는 초기 로딩 단계에서 네트워크 왕복 횟수가 증가한다는 점이다. 여러 요청이 동시에 발생하면 가장 늦게 도착한 응답이 병목이 되어 로딩이 길어지고, 결과적으로 사용자 체감이 느려진다.

두 번째 문제는 화면 상태의 불일치다. 사용자 정보가 먼저 로드되면 닉네임 같은 영역만 먼저 채워지고, 채팅 리스트는 잠시 비어 있다가 뒤늦게 채워진다. 반대로 채팅 리스트가 먼저 로드되면 사용자 정보가 없는 상태로 일부 UI가 placeholder 형태로 남는다. 어느 한 요청만 실패할 경우에는 화면의 일부만 실패한 상태가 남아 UX 일관성이 무너진다.

### 1.3 구조적으로 드러난 한계

근본 원인은 화면 단위 데이터 조합 책임이 프론트엔드에 과도하게 집중되어 있다는 점이다. 프론트엔드는 어떤 API를 호출할지 결정하고, 병렬 요청을 조율하고, 응답을 조합하고, 실패 처리를 담당한다. 즉, 화면 하나를 그리기 위해 프론트가 데이터 조합기와 상태 관리자의 역할을 동시에 수행하고 있다.

이 구조는 다음 문제로 이어진다.

- 화면마다 유사한 조합 로직이 반복됨
- 새로운 데이터 요구가 생길 때마다 화면 로직 복잡도 증가
- 서버 입장에서는 이 요청이 어떤 화면을 위한 것인지 알기 어려워, 화면 단위 캐싱 전략 적용이 어렵다

### 1.4 BFF 데이터 집계 필요성

화면 단위에서 항상 함께 쓰이는 데이터라면, 데이터 조합 책임을 프론트에서 서버로 옮기는 것이 더 합리적이다. App Router 구조에서는 BFF 라우트를 자연스럽게 둘 수 있으므로, 이 역할을 BFF가 맡도록 설계하는 것이 구조적으로도 적절하다.

핵심 질문은 단순하다.

> “항상 함께 쓰는 데이터인데, 왜 프론트에서 따로따로 불러오고 있는가?”

이 질문에 대한 답이 BFF 집계 도입의 배경이 된다.

### 1.5 설계 방향

설계 방향은 다음과 같다.

- 화면 단위로 하나의 BFF 엔드포인트를 제공한다
- 프론트엔드는 더 이상 여러 API를 조합하지 않는다
- upstream API 호출 순서, 실패 처리, 데이터 조합은 BFF 책임이다
- 프론트는 성공/실패 상태만 명확히 구분한다

이 방식은 프론트엔드를 “데이터를 만드는 쪽”이 아니라 “완성된 데이터를 표현하는 쪽”으로 제한한다.

### 1.6 채팅 리스트 화면 집계 적용 예시

채팅 리스트 화면은 구조적으로 집계 대상이 가장 명확하다. 현재 화면은 `getUserMe()`와 `getChatList()`를 동시에 호출하고, 각각의 결과를 결합해 화면을 구성한다. 이 조합을 BFF로 이동하면 프론트 로직이 단순해지고 로딩 상태도 일관되게 관리할 수 있다.

집계 API는 다음과 같이 정의하는 것이 합리적이다.

- 엔드포인트(설계): `GET /app/bff/chat/summary`
- 역할: 사용자 정보 + 채팅 리스트를 단일 응답으로 제공

여기서 중요한 점은 “현재 코드에 이 라우트가 존재한다”가 아니라, “집계 적용 시 이렇게 정의하는 것이 맞다”는 설계 관점이다. 실제 구현은 이후 단계에서 추가된다.

### 1.7 프론트엔드 구조 변화

집계 도입 이후, 프론트의 흐름은 다음과 같이 정리된다.

- 기존: 화면 진입 → 여러 API 호출 → 응답 조합 → 상태 판단
- 변경: 화면 진입 → 집계 API 1회 호출 → 결과 렌더링

이 변화로 인해 프론트는 더 이상 “유저 정보는 있는데 채팅은 없는 상태” 같은 중간 케이스를 고려하지 않아도 된다. 로딩/에러/성공 상태가 화면 단위로 명확해진다.

### 1.8 이 변경이 만들어내는 구조적 효과

이 작업은 단순히 요청 수를 줄이는 수준이 아니라, 책임 경계 자체를 재정의한다. 프론트는 표현에 집중하고, 서버는 조합과 정책에 집중한다. 이후 SSE나 스트리밍 같은 실시간 기능 확장도 “화면 단위 데이터 집계가 이미 존재한다”는 전제 위에서 훨씬 자연스럽게 붙일 수 있다.


---

## [1] BFF 사이드 캐싱

### 1.7 캐싱이 필요한 이유

BFF에서 집계 응답을 만들면 동일한 화면 요청이 많을 때 중복 계산 비용이 발생한다. 특히 비로그인 기반, 혹은 동일 사용자 요청이 짧은 시간에 반복될 경우 캐싱 효과가 크다.

### 1.8 캐싱 범위 구분

1. 공개 데이터
   - 캐시 허용 범위: `public` + `max-age` + `stale-while-revalidate`
   - 예: 홈 배너, 공지, 추천 리스트

2. 사용자별 데이터
   - 캐시 허용 범위: `private` 또는 `no-store`
   - 예: `user/me`, 채팅 리스트

### 1.9 BFF 캐싱 적용 방식

1. Next fetch 캐시
   - `fetch`에 `next: { revalidate: N }` 설정
   - 사용자별 데이터는 `cache: 'no-store'`

2. 응답 캐시 헤더
   - BFF 응답에 `Cache-Control` 추가

### 1.10 예시 (공개 데이터 캐시)

```ts
const res = await fetch(buildApiUrl('/api/v1/public/banner'), {
  next: { revalidate: 60 },
});

return NextResponse.json(data, {
  headers: {
    'Cache-Control': 'public, max-age=60, stale-while-revalidate=300',
  },
});
```

### 1.11 기대 효과

- API 서버 부하 감소
- 반복 요청에서 TTFB 개선
- 사용자 체감 로딩 개선

---

## [2] 캐싱 전략 (Next + Zustand + TanStack + Service Worker)

이 프로젝트에서 캐싱은 “어디서 데이터를 저장할 것인가”의 문제가 아니라, “어떤 레이어가 어떤 책임을 가질 것인가”의 문제다. 캐시를 여러 곳에 분산시키면 순간적으로는 빨라 보이지만, 시간이 지날수록 동기화 비용과 오류 가능성이 급격히 증가한다. 그래서 이 문서에서는 레이어를 단순화하고, 코드에서 일관되게 적용할 수 있는 규칙을 먼저 정의한다.

### 2.1 기본 원칙

이 프로젝트의 캐싱 레이어는 다음 네 가지로 구분한다.

- Next fetch 캐시와 ISR: 공개 데이터, SEO 페이지, 비로그인 상태에 쓰이는 데이터
- TanStack Query: 로그인 이후 사용자 상호작용 데이터
- Zustand: UI 상태 전용
- Service Worker: 정적 자산과 오프라인 전용, API 캐시는 최소화

이 구조의 핵심은 “데이터 캐시”와 “UI 상태”를 분리하는 것이다. 데이터 캐시는 네트워크 원본과 동기화 규칙이 필요하지만, UI 상태는 단순히 화면의 현재 상태만 기억하면 된다. 이 둘을 섞으면 업데이트 타이밍이 꼬이고, 디버깅 비용이 폭발적으로 증가한다.

### 2.2 Next fetch 캐시 + ISR 적용 방식

Next의 fetch 캐시는 서버 측에서 동작하는 데이터 캐싱이다. 이 프로젝트에서는 공개형 데이터에만 사용한다. 즉, 로그인 여부와 무관하며 여러 사용자가 동일하게 보는 데이터에 적합하다.

예를 들어 홈 화면에서 보여주는 배너, 공지, 공개 전문가 리스트가 여기에 해당할 수 있다. 이런 데이터는 자주 바뀌지 않고, 같은 페이지를 여러 사용자가 동시에 조회하기 때문에 서버 캐시 효율이 매우 좋다.

적용 기준은 다음과 같다.

- 사용자가 로그인하지 않아도 볼 수 있는 데이터
- 일정 시간 동안 동일 응답을 유지해도 문제가 없는 데이터
- SEO가 필요한 페이지에서 사전 렌더링이 유리한 데이터

코드에서는 다음과 같은 형태로 적용한다.

```ts
const res = await fetch(buildApiUrl('/api/v1/public/banner'), {
  next: { revalidate: 60 },
});
```

반대로 `user/me`, 채팅 리스트, 개인 설정처럼 사용자별 데이터는 `cache: 'no-store'`로 고정한다. 이건 서버 캐시에 들어가면 안 되는 데이터이기 때문이다.

### 2.3 TanStack Query 적용 방식

이 프로젝트에서 TanStack Query는 “로그인 상태 이후의 사용자 데이터 캐시”를 맡는다. 즉, 사용자별 응답을 유지하면서도 일정 시간 동안 재요청을 줄여야 하는 영역에 사용한다.

이 구조는 특히 `user/me` 중복 호출을 줄이는데 효과적이다. 예를 들어 `ChatList`처럼 여러 화면에서 `user/me`를 참조하는 경우, 각각의 화면에서 별도로 호출하면 동일 요청이 반복된다. TanStack Query의 캐시는 이를 막아준다.

적용 대상은 다음과 같다.

- 로그인 이후 사용자 정보(`user/me`)
- 사용자 상호작용으로 자주 변하는 데이터(채팅 리스트, 알림)
- 페이지 이동 시 재요청을 줄여야 하는 데이터

정책 예시는 다음처럼 정한다.

- `staleTime`: 60초
- `gcTime`: 10분
- 로그인/로그아웃/프로필 수정 시 `invalidateQueries`로 명시 갱신

```ts
useQuery({
  queryKey: ['user-me'],
  queryFn: getUserMe,
  staleTime: 60 * 1000,
  gcTime: 10 * 60 * 1000,
});
```

이렇게 하면 동일 세션 내에서 `user/me` 호출이 반복되는 것을 막으면서, 사용자 정보가 변경되었을 때는 명시적으로 갱신할 수 있다.

### 2.4 Zustand 적용 방식

Zustand는 이 프로젝트에서 “UI 상태”만 담당한다. 데이터 캐시는 절대 넣지 않는다. 이 원칙이 깨지면 상태가 어디서 갱신되는지 추적하기 어려워진다.

적용 대상은 다음과 같다.

- 모달 열림/닫힘
- 필터 UI 선택값
- 페이지 내 탭 전환 상태

```ts
import { create } from 'zustand';

type UiState = {
  isSidebarOpen: boolean;
  toggleSidebar: () => void;
};

export const useUiStore = create<UiState>((set) => ({
  isSidebarOpen: false,
  toggleSidebar: () => set((s) => ({ isSidebarOpen: !s.isSidebarOpen })),
}));
```

실제 데이터(예: 전문가 리스트, 채팅 메시지)는 여기에 넣지 않는다. 이 데이터는 캐싱 규칙과 동기화 전략이 필요한 영역이므로 TanStack Query 또는 서버 캐시에 맡기는 것이 맞다.

### 2.5 Service Worker 적용 방식

Service Worker는 강력하지만 잘못 쓰면 데이터 불일치를 만드는 위험한 도구다. 이 프로젝트에서는 정적 자산 캐시 전용으로 제한하는 것이 안전하다.

적용 대상은 다음과 같다.

- 정적 이미지, 폰트, JS 번들
- 오프라인 지원이 필요한 경우의 기본 shell

API 캐시는 “특정 케이스에서만” 적용한다. 예를 들어 푸시 알림이나 오프라인 읽기 전용 콘텐츠처럼, 데이터 최신성이 중요하지 않은 경우에만 제한적으로 적용한다.

### 2.6 레이어가 겹치지 않도록 하는 규칙

레이어 간 중복을 막기 위한 규칙을 명확히 둔다.

1. 서버 캐시는 공개 데이터만\n+2. 사용자 데이터는 TanStack Query에서만 캐싱\n+3. UI 상태는 Zustand만 사용\n+4. Service Worker는 정적 자산 전용

이 규칙을 지키면 데이터는 항상 “하나의 진실 소스”를 가진다. 문제 발생 시 어디를 보면 되는지 명확해지고, 캐시 무효화 정책이 단순해진다.

### 2.7 프로젝트 기준 적용 지점 정리

- 홈 화면: 공개 데이터는 Next fetch 캐시 + ISR, UI 상태는 Zustand\n- 채팅 리스트: 사용자 데이터는 TanStack Query, 실시간 갱신은 SSE로 확장\n- 마이페이지: 사용자 정보 TanStack Query, UI 상태 Zustand\n- 전문가 검색: 공개 검색 결과는 ISR, 필터 UI는 Zustand\n
이 구조로 정리하면 캐시 레이어가 서로 충돌하지 않고, 성능 최적화와 유지보수성을 동시에 확보할 수 있다.

---

## [3] 렌더링 최적화 (이미지, 폰트)

### 3.1 이미지 최적화

적용 지점

- 프로필 이미지
- 홈 배너, 아이콘
- 검색 결과 카드

핵심 개선

1. 원격 이미지 `remotePatterns` 등록 후 `unoptimized` 제거
2. LCP 이미지에만 `priority` 적용
3. `sizes` 속성으로 디바이스별 적절한 크기 제공

예시

```ts
// next.config.mjs
const nextConfig = {
  images: {
    remotePatterns: [
      {
        protocol: 'https',
        hostname: 'your-cdn-domain.com',
      },
    ],
  },
};

export default nextConfig;
```

```tsx
<Image
  src={expert.profile_image_url || defaultUserImage}
  alt="프로필"
  width={72}
  height={72}
  sizes="(max-width: 768px) 64px, 72px"
/>
```

### 3.2 폰트 최적화

적용 지점

- `src/shared/config/font.ts`

핵심 개선

1. 실제 사용하는 weight만 로드
2. 가중치 단계적 확장

예시

```ts
export const pretendard = localFont({
  src: [
    { path: '../asset/fonts/Pretendard-Regular.woff2', weight: '400' },
    { path: '../asset/fonts/Pretendard-Medium.woff2', weight: '500' },
    { path: '../asset/fonts/Pretendard-Bold.woff2', weight: '700' },
  ],
  display: 'swap',
  variable: '--font-pretendard',
});
```

### 3.3 기대 효과

- 이미지 전송량 감소
- 폰트 로딩 비용 감소
- LCP 및 FCP 개선

---

## [4] SEO 최적화

### 4.1 적용 지점

1. 홈 페이지
2. 전문가 검색 및 상세 페이지
3. 채팅, 마이페이지 등 로그인 전 접근 가능한 페이지

### 4.2 키워드 분석 방향 (서비스 특성 기반)

서비스는 "커리어/전문가 매칭", "채팅", "이력서/직무 상담" 성격을 가진다. 따라서 다음 키워드 군이 기본 축이다.

1. 커리어 상담
2. 이력서 피드백
3. 현직자 멘토링
4. 직무 전환
5. 채팅 기반 상담

### 4.3 메타데이터 설계 예시

```ts
export const metadata: Metadata = {
  title: 'RE:FIT | 현직자 멘토링과 커리어 상담',
  description: '현직자와 대화하며 이력서 피드백과 직무 상담을 받을 수 있습니다.',
  openGraph: {
    title: 'RE:FIT | 현직자 멘토링과 커리어 상담',
    description: '직무 전환, 이력서 피드백, 커리어 상담을 한 번에.',
    images: ['/og/main.png'],
  },
  twitter: {
    card: 'summary_large_image',
  },
};
```

### 4.4 구조화 데이터

- `Organization`
- `FAQPage`
- `WebSite` + `SearchAction`

예시

```tsx
const jsonLd = {
  '@context': 'https://schema.org',
  '@type': 'Organization',
  name: 'RE:FIT',
  url: 'https://your-domain.com',
  logo: 'https://your-domain.com/icons/char_icon.png',
};
```

### 4.5 기대 효과

- 검색 노출 증가
- 페이지 CTR 개선
- 브랜드 신뢰도 강화

---

## [5] 채팅 리스트 폴링 → SSE

이 섹션은 현재의 1초 폴링 구조를 “잘못된 선택”으로 규정하지 않는다. 오히려 지금의 의도가 무엇이었는지 인정한 뒤, 그 구조가 가진 한계를 명확히 짚고, SSE로 자연스럽게 계승하고 확장하는 방향을 서술한다. 톤은 기존 설계 문서와 동일하게 유지한다.

### 5.1 현재 채팅 리스트 업데이트 구조

현재 채팅 리스트 화면은 1초 주기의 폴링으로 갱신된다. 실제 구현은 `src/widgets/chat-list/ui/ChatList.tsx`에서 확인할 수 있으며, 인증 상태가 `authed`인 경우에만 폴링이 시작된다. 또한 브라우저가 백그라운드로 내려가면 `document.visibilityState`를 확인해 폴링 호출을 건너뛰고, 탭이 다시 활성화되거나 포커스를 얻으면 즉시 재요청을 수행한다.

매 1초마다 실행되는 요청은 2개다. 하나는 `getUserMe()`이고, 다른 하나는 `getChatList()`다. 두 요청은 `Promise.allSettled`로 병렬 실행된다. 채팅 카운트는 별도의 API가 아니라 채팅 리스트 응답의 `unread_count`를 사용한다.

이 구조는 단순하지만, “화면이 열려 있는 동안에는 거의 실시간처럼 보이게 만든다”는 목적을 명확히 달성하고 있다.

### 5.2 이 구조가 의도적으로 선택된 이유

채팅 UX에서 핵심은 “새 메시지가 왔다는 사실을 사용자가 얼마나 빨리 인지하느냐”다. 이 경험이 느려지면 채팅 앱 전체에 대한 신뢰가 흔들린다. 그래서 이 프로젝트에서는 다음을 우선순위로 뒀다.

1. 새 메시지가 도착한 직후 최대 1초 안에 리스트에서 카운트를 갱신한다.\n+2. 사용자가 별도로 새로고침하지 않아도 상태가 갱신된다.\n+3. 구현 복잡도를 낮게 유지해 안정적으로 운영한다.

1초 폴링은 이 요구사항을 가장 확실하고 단순한 방식으로 만족시킨다. 이는 임시방편이 아니라 UX를 최우선으로 고려한 의도적인 선택이다.

### 5.3 폴링이 제공한 장점과 동시에 드러난 한계

폴링은 구조적으로 단순하다. 네트워크 오류가 발생해도 다음 폴링에서 복구되고, 연결 상태 관리가 어렵지 않다. 이 점은 초기 운영 안정성에서 중요한 장점이었다.

하지만 사용자가 늘어나면 구조적 한계가 즉시 드러난다. 1초 주기 폴링은 사용자 1명 기준으로도 시간당 7,200번의 요청을 만든다. 동시 사용자 수가 늘어나면 트래픽이 기하급수적으로 증가한다. 그리고 이 요청의 대부분은 “변경이 없는 상태 확인”이다. 즉, 실제로는 의미 없는 요청이 서버와 네트워크 자원을 계속 소모한다.

또 하나의 한계는 “실시간처럼 보이지만 결국 폴링”이라는 점이다. 지연을 1초보다 줄이려면 폴링 주기를 더 줄여야 하고, 그 순간 비용은 감당하기 어려운 수준으로 급증한다. 구조적으로는 이벤트 기반이 아니라 여전히 주기적 확인 방식이기 때문에, 실시간성과 비용을 동시에 잡기 어렵다.

### 5.4 문제의 본질을 다시 정의하기

이 시점에서 문제는 “상태 조회”가 아니라 “상태 변경 이벤트 전달”로 재정의된다. 즉, 매초 “바뀌었는지” 묻는 구조 대신, “바뀌었을 때만 알려주는 구조”로 이동하는 것이 맞다. 이 사고의 전환이 SSE 전환의 출발점이다.

### 5.5 SSE로의 자연스러운 계승

SSE는 현재 요구사항과 정확히 일치한다. 채팅 리스트 업데이트는 서버에서만 변경이 발생하고, 클라이언트가 서버로 지속적인 양방향 통신을 할 필요가 없다. 변경은 불규칙하게 발생하며, 변경이 없는 시간에는 네트워크 요청이 없어야 이상적이다. 이 특성은 SSE의 설계 목적과 동일하다.

SSE를 도입하면 폴링이 제공하던 “실시간처럼 느껴지는 UX”는 그대로 유지되며, 오히려 실제로는 더 빠른 반영이 가능하다. 즉, 이 전환은 기존 선택을 부정하는 것이 아니라, 그 선택의 장점을 그대로 유지하면서 비용 구조만 바꾸는 확장이다.

### 5.6 역할 분리와 적용 범위

SSE는 모든 것을 대체하지 않는다. 역할을 명확히 나누는 것이 중요하다.

1. 초기 상태 로딩은 BFF 집계 응답으로 처리한다. 예를 들어 `GET /bff/chat/summary` 같은 형태로 화면 초기 데이터를 단일 응답으로 내려준다.\n+2. 이후 변경 이벤트만 SSE가 담당한다. 예를 들어 `GET /sse/chat-list`로 연결한 뒤, 변경이 있을 때만 `update` 이벤트를 푸시한다.

이 방식은 초기 렌더와 실시간 갱신을 분리해, 구현과 운영을 모두 단순하게 만든다.

### 5.7 전환 전략

현재 폴링 구조가 UX적으로 중요했기 때문에, 전환은 단계적으로 진행한다.

1. SSE 연결을 먼저 시도한다.\n+2. 연결 성공 시 폴링을 중단하고 SSE만 사용한다.\n+3. SSE 연결 실패 시에는 기존 1초 폴링을 유지한다.\n+4. 안정성 지표가 충분히 확보되면 폴링을 제거한다.

이 전략은 “현재 UX를 유지한 채로 구조만 전환한다”는 요구에 정확히 부합한다.

### 5.8 결론

현재의 1초 폴링 구조는 UX 관점에서 성공적이었다. 다만 이는 “지금 당장의 실시간성”을 위해 “지속 가능한 비용”을 일부 희생한 선택이었다. SSE 전환은 이 트레이드오프를 해소하는 작업이다. 기존 구조를 부정하는 것이 아니라, 그 구조의 장점을 계승하면서 비용을 줄이고 확장성을 확보하는 방식이다.

---

## [6] 추가 사항

### 6.1 리스트 가상화

적용 지점

- 채팅 리스트
- 전문가 검색 결과

기대 효과

- 스크롤 성능 개선
- 렌더 비용 감소

### 6.2 하이드레이션 축소

적용 지점

- 홈 페이지 상단 영역
- 상호작용이 없는 UI

기대 효과

- 초기 인터랙션 지연 감소
- 모바일 체감 성능 개선

### 6.3 메트릭 기반 개선 루프

적용 지점

- `MetricsInitializer`에 Web Vitals 로그 연결
- 개선 전/후 비교 기록

기대 효과

- 투자 대비 효과 측정
- 성능 회귀 탐지
